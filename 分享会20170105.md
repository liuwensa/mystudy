## web性能优化
进行优化前，关键是剖析当前的web性能，找到性能瓶颈，从而确定最需改进的地方;
如果精力有限，首先将精力放在能明显提升性能的改进点上;

《高性能网站建设指南》提出了一个性能黄金法则：
只有10%-20%的最终用户响应时间花在了下载HTML文档上;其余的80%-90%的时间花在了下载页面中的所有组件上。

web性能对于用户体验有及其重要的影响，根据著名的2-5-8原则：

当用户在2秒以内得到响应，会感觉系统的响应非常快；
当用户在2-5秒之内得到响应，会感觉系统的响应速度还可以；
当用户在5-8秒之内得到响应，会感觉系统的响应非常慢，但还可以接受；
当用户在8秒之后都没有得到响应，会感觉系统糟透了，甚至系统已经挂掉；要么打开竞争对手的网站，要么重新发起第二次请求。

## 后台优化，启用静态页面，启用redis缓存;
服务端的接口优化，使用索引加速数据库查询，redis缓存
网站生成静态页面
公共的网站头部、尾部、侧边栏等写入静态页或者redis重复利用

## NGINX
开启Gzip压缩文件内容
如果应用运行在一台独立的服务器上，性能问题的解决方案很简单：换一台叼的服务器

但这可能不是问题所在，所以应该采用一种完全不同的方式，而不是升级硬件。

- 负载均衡：反向代理服务器上运行一个负载均衡器，把流量平均分配给一堆应用服务器。由于负载均衡器的引入，在增加应用服务器时可以完全不用修改应用程序。

- 缓存静态文件：直接请求的文件，比如图片或者代码文件，可以存在反向代理服务器上，并直接发送给客户端，这样可以更快地提供服务，分担了应用服务器的负载，可以让应用执行得更快。

- 保护网站 —— 反向代理服务器可以设置较高的安全级别，通过监控进快速识别和响应攻击，这样就可以把应用服务器保护起来。

NGINX软件是专门设计用做反向代理服务器的，NGINX通常被用于负载均衡，NGINX利用事件驱动处理的方法，比其它传统的服务器更加高效。

## 合并压缩
合并css、js等文件，更少的HTTP请求和单个文件解析都可以减少加载时间
压缩去除代码不必要的字符减少文件大小从而节省下载时间。
即使你用Gzip压缩过脚本和样式表，合并压缩这些文件仍然可以节省空间。


## 图片加载
图片用缩略图
懒加载、按需加载。

图片懒加载有着显著的三个好处：

- 减少向服务器发出的并发请求数量（这就使得页面的其他部分获得更快的加载时间）

- 减少浏览器的内存使用率（更少的图片，更少的内存）

- 减少服务器端的负载



# 敏感词过滤
敏感词过滤，一个很经典的需求场景，游信中贴吧、动态、聊天等需要敏感词过滤功能，之前的解决方案是，每次从redis中取出敏感词集合，然后做遍历操作，使用indexOf查看是否出现。

- DFA算法：trie存储，牺牲空间换效率；

- indexOf算法：自带算法

## DFA简介
敏感词过滤的算法中，DFA是唯一比较好的实现算法。DFA是确定有穷自动机，它是是通过event和当前的state得到下一个state，即event+state=nextstate。下图展示了其状态的转换
![](http://img.blog.csdn.net/20140525154027187?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2hlbnNzeQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

在这幅图中大写字母（S、U、V、Q）都是状态，小写字母a、b为动作。通过上图我们可以看到S+a=U,U+a=Q,S+b=V等等。

## 敏感词过滤

在文字过滤系统中，为了能够应付较高的并发，有一个目标比较重要，就是尽量的减少计算，而在DFA中，基本没有什么计算，有的只是状态的转移。而要把敏感词列表构造成一个状态机，用矩阵来实现是比较麻烦的，下面介绍一种比较简单的实现方式，就是树结构。 

首先我们对上图进行剖析。在这过程中我们认为下面这种结构会更加清晰明了
![](http://img.blog.csdn.net/20140525154009593?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2hlbnNzeQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
  同时这里没有状态转换，没有动作，有的只是查找（query）。我们可以认为，通过S query U、V，通过U query V、P，通过V query U P。通过这样的转变我们可以将状态的转换转变为使用集合的查找。

诚然，加入在我们的敏感词库中存在如下几个敏感词：日本人、日本鬼子。那么我需要构建成一个什么样的结构呢？
首先：query 日 ---> {本}、query 本 --->{人、鬼子、男人}、query 人 --->{null}、query 鬼 ---> {子}、query 男 ---> {人}。形如下结构：
![](http://i.imgur.com/jLIBe7n.png)

 这样我们就将我们的敏感词库构建成了一个类似与一颗一颗的树，这样我们判断一个词是否为敏感词时就大大减少了检索的匹配范围。比如我们要判断日本人，根据第一个字我们就可以确认需要检索的是那棵树，然后再在这棵树中进行检索。
 但是如何来判断一个敏感词已经结束了呢？利用标识位来判断。所以对于这个关键是如何来构建一棵棵这样的敏感词树。

![](http://i.imgur.com/yauyy0z.png)

检索

![](http://i.imgur.com/rRB8K7h.png)

当然你可以防盗搜索引擎中做，引擎的分词可以降低被误伤的概率

# 动态、贴吧缓存设计
1. hash，查出全部贴吧id列表放入redis缓存
2. Redis的zset结构做存储，天然有序，支持原子的增/删/查询操作。

动态实现分为：推（push）模式和拉（pull）模式

1. 推的模式： 
A发布动态之后，异步读取A的每个好友，并把这条动态插入到每个好友的动态列表。

	- 好处：读取效率高，可以看作O(1)的操作。
 
	- 坏处：写操作开销大，每秒1000条动态，每人N个好友，需要1000*N写操作，而且一个动态重复保存N次，产生大量冗余数据。随着用户产生数据的积累，长尾效应明显，冷数据占比会越来越高。而且redis对小zset采用压缩双链表（ziplist）的方式紧凑存储，列表增长会转换为跳跃表（skiplist），内存利用率下降。


2. 拉模式：根据用户的好友关系和个人动态列表，找到上次访问之后产生的新动态，增量实时聚合新内容。
 大致步骤：

	- 遍历我的好友，找到最近发表过动态的人

	- 遍历最近发表过动态，得到id和time

	- 合并到我的动态列表

聚合过程采用多线程并行执行，对查询性能影响很小。

拉模式，冷数据可以被淘汰删除，只缓存最近的热点数据，解决了存储成本高的问题。

# 附近的人
## 第一个版本：
最简单的方法就是遍历一遍，然后使用经纬度计算距离。计算公式是：
![](http://i.imgur.com/4TNCKC4.png)
r是地球半径，φ1, φ2是两点纬度，λ1, λ2是两点的经
这样的话，每次搜索附近的人，都可以通过公式计算出来附近x km的经纬度范围，然后去数据库查询。这样的缺点就是每次生成的sql语句都不一样，很难缓存，毕竟附近的人不是特别精确的，只要两个人在同一个范围内就可以认为是在一起的。

## 第二个版本，mongo的2D索引实现空间查询
find({location : {"$near" : [39.9937,116.4361]}}).sort({time:-1});

本来认为mongo自带索引应该效率会很好的，由于mongo的2D查询不能建立联合索引，按时间排序的话，性能比较低，超过100ms。通过数据文件挂载在内存盘上和按地理位置partition的方法，做了一些优化，效果还是不理想。并且很吃cpu，压力测试的时候8核cpu，吃了6核。

## 第三个版本，采用geohash算法实现了更高效的空间查询
但是还没实现，这个功能直接砍掉了

